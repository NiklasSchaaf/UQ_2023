{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "from scipy.stats import multivariate_normal, gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def determ(u):\n",
    "    '''\n",
    "    Deterministic function\n",
    "\n",
    "    Arguments:\n",
    "        u -- input vector\n",
    "\n",
    "    Returns:\n",
    "        deterministic model output value\n",
    "    '''\n",
    "    alpha, beta = u\n",
    "    return 1.5*alpha + 0.25*(beta-1)**2 + np.cos(np.pi+alpha+beta)\n",
    "\n",
    "def func(u):\n",
    "    '''\n",
    "    Adds noise to deterministic model\n",
    "\n",
    "    Arguments:\n",
    "        u -- input vector\n",
    "\n",
    "    Returns:\n",
    "        noisy model output value\n",
    "    '''\n",
    "    return determ(u)+np.random.normal(0,0.1)\n",
    "\n",
    "def prior(u,sigma=0.25):\n",
    "    '''\n",
    "    Prior PDF of multivariate normal centered at (0,4)\n",
    "\n",
    "    Arguments:\n",
    "        u -- input vector\n",
    "\n",
    "    Keyword Arguments:\n",
    "        sigma -- scale of distribution (default: {0.25})\n",
    "\n",
    "    Returns:\n",
    "        probability of input vector\n",
    "    '''\n",
    "    return multivariate_normal.pdf(u, mean = [0,4], cov = sigma**2)\n",
    "\n",
    "def prior_costas(u_prop, u):\n",
    "    mean = np.array([0,4])\n",
    "    return np.exp((np.linalg.norm(u - mean) ** 2 - np.linalg.norm(u_prop - mean) ** 2) / (2 * 0.25 ** 2))\n",
    "\n",
    "@njit\n",
    "def proposal(u,sigma):\n",
    "    '''\n",
    "    Generates a new proposal from normal distribution.\n",
    "\n",
    "    Arguments:\n",
    "        u -- input vector\n",
    "        sigma -- scale of normal distribution\n",
    "\n",
    "    Returns:\n",
    "        proposal vector\n",
    "    '''\n",
    "    alpha, beta = u\n",
    "    alpha = alpha + np.random.normal(0,sigma)\n",
    "    beta = beta + np.random.normal(0,sigma)\n",
    "    return np.array([alpha, beta])\n",
    "\n",
    "def likelihood_ratio(u_prop,u,data,sigma=0.1):\n",
    "    '''\n",
    "    Calculates the likelihood ratio for a proposal based on the model\n",
    "\n",
    "    Arguments:\n",
    "        u_prop -- proposal vector\n",
    "        u -- current vector\n",
    "        data -- data vector\n",
    "\n",
    "    Keyword Arguments:\n",
    "        sigma -- scale of the observation error (default: {0.1})\n",
    "\n",
    "    Returns:\n",
    "        _description_\n",
    "    '''\n",
    "    u_prop_sum = np.sum(np.subtract(data,determ(u_prop))**2)\n",
    "    u_sum = np.sum(np.subtract(data,determ(u))**2)\n",
    "    return np.exp(1/(2*sigma**2) * (-u_prop_sum + u_sum))\n",
    "\n",
    "def accept_prob(u_prop,u,data):\n",
    "    '''\n",
    "    Calculates the acceptance probability\n",
    "\n",
    "    Arguments:\n",
    "        u_prop -- proposal vector\n",
    "        u -- current vector\n",
    "        data -- data vector\n",
    "\n",
    "    Returns:\n",
    "        acceptance probability\n",
    "    '''\n",
    "    ratio = prior(u_prop)/prior(u)\n",
    "    ratio = ratio * likelihood_ratio(u_prop,u,data)\n",
    "    return np.min([1,ratio])\n",
    "\n",
    "def metropolis_hastings(steps,data,sigma=1,u0 = np.array([0,0])):\n",
    "    '''\n",
    "    Metropolis Hastings algorithm to sample the posterior distribution\n",
    "\n",
    "    Arguments:\n",
    "        steps -- number of MCMC steps\n",
    "        data -- data vector\n",
    "\n",
    "    Keyword Arguments:\n",
    "        sigma -- scale of the proposal distribution (default: {1})\n",
    "        u0 -- initial vector (default: {np.array([0,0])})\n",
    "\n",
    "    Returns:\n",
    "        samples -- array of sample vectors\n",
    "        probs -- array with acceptance probabilities\n",
    "    '''\n",
    "    samples = np.zeros((steps+1,2))\n",
    "    probs = np.zeros(steps)\n",
    "    samples[0] = u0\n",
    "\n",
    "    accepted = 0\n",
    "    for i in range(steps):\n",
    "        \n",
    "        u_prop = proposal(samples[i],sigma)\n",
    "        probs[i] = accept_prob(u_prop, samples[i],data)\n",
    "\n",
    "        if probs[i] >= np.random.rand():\n",
    "            samples[i+1] = u_prop\n",
    "            accepted += 1\n",
    "        else:\n",
    "            samples[i+1] = samples[i]\n",
    "\n",
    "    return samples, probs, accepted/steps\n",
    "\n",
    "# data vector\n",
    "data = np.array([4.02, 3.97, 4.05, 3.85, 3.94])\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.linspace(0.1,0.2,11)\n",
    "acc_r = np.zeros(len(std))\n",
    "\n",
    "for i in range(len(std)):\n",
    "    _,_,acc_r[i]  = metropolis_hastings(50_000,data,sigma=std[i], u0 = np.array([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,2.5))\n",
    "plt.fill_between([0, 0.5],[0.25, 0.25],[0.3, 0.3],color='grey',alpha=0.2)\n",
    "plt.plot(std,acc_r, marker='.')\n",
    "plt.ylabel('acceptance probability')\n",
    "plt.xlabel('standard deviation of the proposal')\n",
    "plt.xlim([0.09,0.21])\n",
    "plt.tight_layout()\n",
    "plt.savefig('tuning.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 101_000\n",
    "samples, probs, acc_rate = metropolis_hastings(steps,data,sigma=0.13, u0 = np.array([0,0])) # 0.13\n",
    "print('acceptance rate:', acc_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale plots nicely to data\n",
    "min_alpha = np.min(samples[:,0])\n",
    "max_alpha = np.max(samples[:,0])\n",
    "min_beta = np.min(samples[:,1])\n",
    "max_beta = np.max(samples[:,1])\n",
    "pad_alpha = 7-(max_alpha-min_alpha)\n",
    "pad_beta = 7-(max_beta-min_beta)\n",
    "\n",
    "N = 100\n",
    "a = np.linspace(min_alpha-pad_alpha,max_alpha+pad_alpha,N)\n",
    "b = np.linspace(min_beta-pad_beta,max_beta+pad_beta,N)\n",
    "deterministic_out = np.zeros((N,N))\n",
    "\n",
    "# calculate deterministic function values for background\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        deterministic_out[i,j] = determ(np.array([a[i],b[j]]))\n",
    "\n",
    "A,B = np.meshgrid(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a gaussian kde on a regular grid of nbins x nbins over data extents\n",
    "nbins=300\n",
    "k = gaussian_kde(samples.T)\n",
    "xi, yi = np.mgrid[-0.5:1.5:nbins*1j, 4:6:nbins*1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.5,3.3))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolor(A,B,deterministic_out)\n",
    "plt.colorbar(label = 'deterministic model output')\n",
    "cont = plt.contour(A,B,deterministic_out, colors='w', alpha = 0.5)\n",
    "plt.clabel(cont, inline=1, fontsize=10)\n",
    "plt.plot(samples[:,0],samples[:,1], c='C1', marker='.')\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('alpha')\n",
    "\n",
    "# zoomed in plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolor(xi, yi, zi.reshape(xi.shape), shading='auto',cmap='Blues')\n",
    "plt.colorbar(label = 'Gaussian KDE')\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('alpha')\n",
    "# plt.xlim([min_alpha2,max_alpha2])\n",
    "# plt.ylim([min_beta2,max_beta2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('MCMC_path.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_a = np.cumsum(samples[:,0])/np.arange(1,steps+2)\n",
    "running_b = np.cumsum(samples[:,1])/np.arange(1,steps+2)\n",
    "\n",
    "plt.figure(figsize=(7,2.5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(running_a[:5000], label='running mean')\n",
    "plt.plot(samples[:5000,0], alpha = 0.5, label = 'samples')\n",
    "plt.ylim([-1,6])\n",
    "plt.ylabel('alpha')\n",
    "plt.xticks([])\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(running_b[:10_000], label='running mean')\n",
    "plt.plot(samples[:10_000,1],alpha=0.5, label='samples')\n",
    "plt.ylim([-1,6])\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('steps')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('convergence.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate the model output for the samples\n",
    "mod_samp = np.zeros(len(samples))\n",
    "for i, sample in enumerate(samples):\n",
    "    mod_samp[i] = func(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the marignal distributions of alpha and beta\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_size_inches(6,2.5)\n",
    "axs[0].hist(samples[1000:,0],bins=30)\n",
    "axs[0].set_xlabel('alpha')\n",
    "axs[0].set_ylabel('count')\n",
    "axs[0].set_ylim([0,12_500])\n",
    "\n",
    "axs[1].hist(samples[1000:,1],bins=30)\n",
    "axs[1].set_xlabel('beta')\n",
    "axs[1].set_ylim([0,12_500])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "axs[2].hist(mod_samp[1000:], bins=30)\n",
    "axs[2].scatter(data, 300*np.ones_like(data),c='C1',marker='.', label = 'd')\n",
    "axs[2].set_xlabel('model output')\n",
    "axs[2].legend(loc='best')\n",
    "axs[2].set_yticks([])\n",
    "axs[2].set_ylim([0,12_500])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('marginals.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('alpha mean:', samples[1000:,0].mean())\n",
    "print('alpha std:', samples[1000:,0].std())\n",
    "print('beta mean:', samples[1000:,1].mean())\n",
    "print('beta std:', samples[1000:,1].std())\n",
    "print('output mean:', mod_samp.mean())\n",
    "print('output std:', mod_samp.std())\n",
    "print('data mean:', data.mean())\n",
    "print('data std:', data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance matrix for alpha and beta\n",
    "np.cov(samples[1000:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
